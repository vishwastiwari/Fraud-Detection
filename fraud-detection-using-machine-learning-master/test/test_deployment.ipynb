{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This noteboook launches the solution, with a parameter that instructs the instance to run the solution's notebook using papermill, wait for that process to finish, then raise any errors encountered while running the notebook to the build.\n",
    "\n",
    "The _build instance_ will launch the solution using the following parameters, which can be overriden by providing them as enviroment variables in the build settings. Since the build instance is launching the solution, the build project needs to be provided with all the permissions that are necessary to launch the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "BRANCH=\"mainline\"\n",
    "REGION=\"us-west-2\"\n",
    "SOLUTIONS_BUCKET=\"sagemaker-solutions-devo\"\n",
    "SOLUTION_NAME=\"Fraud-detection-using-machine-learning\"\n",
    "STACK_NAME=\"sagemaker-soln-fdml-ci\"\n",
    "STACK_VERSION=\"development\"\n",
    "COMMIT_ID = \"\"\n",
    "CI_BUCKET = \"\"\n",
    "# TODO: Get timeout from build, and divide by 1 min to get number of attempts\n",
    "NOTEBOOK_POLL_ATTEMPTS=120 # Number of attempts while waiting for SM notebook to execute and produce output on S3\n",
    "NOTEBOOK_POLL_DELAY=60 # Delay between each attempt, in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell programmatically creates the URL for the solution's template, based on the parameters passed above. It's important to include the branch suffix to be able to support feature branches as well as the mainline release pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_suffix = \"\" if BRANCH == \"mainline\" else f\"-{BRANCH}\"\n",
    "template_url = f\"https://{SOLUTIONS_BUCKET}-{REGION}.s3.{REGION}.amazonaws.com/{SOLUTION_NAME}{branch_suffix}/deployment/fraud-detection-using-machine-learning.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we create a unique prefix for our solution, and create an S3 bucket that will serve as the destination for the notebook files we run on the SM instance. It's important that its name starts with the solution prefix, as that will allow the solution itself to write to it (because the solution should have write access to all `sagemaker-soln-` buckets under the same account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import uuid\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "\n",
    "\n",
    "cfn_client = boto3.client('cloudformation', region_name=REGION)\n",
    "s3_client = boto3.client('s3', region_name=REGION)\n",
    "s3 = boto3.resource('s3', region_name=REGION)\n",
    "\n",
    "unique_id = uuid.uuid4().hex[:8]\n",
    "\n",
    "# Give the solution a unique prefix\n",
    "solution_prefix = \"sagemaker-soln-fdml-\" # TODO: Get from template directly\n",
    "unique_prefix = f\"{solution_prefix}{unique_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TestOutputsS3Bucket` CloudFormation parameter given in the next cell, is parsed by CloudFormation and taken in by the project's configuration package (see `source/notebooks/src/package/config.py`). When this parameter is set to something different than `\"\"`, the notebook instance will run the solution's notebook using papermill, through the instance's on-start script (see `deployment/fraud-detection-sagemaker-notebook-instance.yaml`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Creating stack using template located at {template_url}\")\n",
    "logging.info(f\"STACK_NAME: {STACK_NAME}\")\n",
    "logging.info(f\"REGION: {REGION}\")\n",
    "logging.info(f\"SOLUTIONS_BUCKET: {SOLUTIONS_BUCKET}\")\n",
    "logging.info(f\"CI_BUCKET: {CI_BUCKET}\")\n",
    "logging.info(f\"StackVersion: {STACK_VERSION}\")\n",
    "logging.info(f\"SolutionPrefix: {unique_prefix}\")\n",
    "\n",
    "cfn_client.create_stack(\n",
    "    StackName=STACK_NAME,\n",
    "    TemplateURL=template_url,\n",
    "    Parameters=[\n",
    "        {\n",
    "            'ParameterKey': 'SolutionPrefix',\n",
    "            'ParameterValue': unique_prefix\n",
    "        },\n",
    "        {\n",
    "            'ParameterKey': 'StackVersion',\n",
    "            'ParameterValue': STACK_VERSION\n",
    "        },\n",
    "        {\n",
    "            'ParameterKey': 'TestOutputsS3Bucket',\n",
    "            'ParameterValue': CI_BUCKET\n",
    "        },\n",
    "        {\n",
    "            'ParameterKey': 'SolutionName',\n",
    "            'ParameterValue': f\"{SOLUTION_NAME}{branch_suffix}\"\n",
    "        }\n",
    "    ],\n",
    "    Capabilities=[\n",
    "        'CAPABILITY_IAM',\n",
    "        'CAPABILITY_NAMED_IAM'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then wait for the stack to finish launching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Waiting for stack creation to complete...\")\n",
    "waiter = cfn_client.get_waiter('stack_create_complete')\n",
    "\n",
    "waiter.wait(StackName=STACK_NAME)\n",
    "logging.info(\"Stack creation complete, notebook run has begun...\")\n",
    "\n",
    "logging.info(\"Notebook instance run logs will be available at:\")\n",
    "logging.info(f\"https://{REGION}.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logsV2:log-groups/log-group/$252Faws$252Fsagemaker$252FNotebookInstances/log-events/{unique_prefix}-notebook-instance$252Frun-notebook.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the stack has finished creating, the OnStart script will attempt to run the `sagemaker_fraud_detection.ipynb` notebook, through the `test/run_notebook.py` script. The notebook is run using papermill, and creates an output in the CI S3 bucket we created previously. The following cell will continuously poll the expected location until the output file appears, or errors out after `NOTEBOOK_POLL_DELAY * NOTEBOOK_POLL_ATTEMPTS` seconds. This also means that the CodeBuild project needs to be able to read files from the particular bucket.\n",
    "\n",
    "Note that if this is longer than the build stage's timeout, the build stage will fail. If your solution's notebooks take very long to run, make sure to [increase the build stage's time out](https://docs.aws.amazon.com/codebuild/latest/userguide/change-project-console.html) as well, can be set using a parameter in the CFT you used to create the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ensure there's a single source for these filenames, either in the config, or passed as a papermill parameter?\n",
    "# Right now they're set here and in run_notebook.py\n",
    "import os\n",
    "prefix = 'integration-test' \n",
    "key = \"output.ipynb\"\n",
    "\n",
    "\n",
    "\n",
    "waiter = s3_client.get_waiter('object_exists')\n",
    "\n",
    "logging.info(f\"Waiting for output notebook to appear at {CI_BUCKET}/{os.path.join(prefix, key)}...\")\n",
    "logging.info(f\"Will attempt a total {NOTEBOOK_POLL_ATTEMPTS} polls every {NOTEBOOK_POLL_DELAY} seconds.\")\n",
    "waiter.wait(Bucket=CI_BUCKET, Key=os.path.join(prefix, key), WaiterConfig={'Delay': NOTEBOOK_POLL_DELAY,'MaxAttempts': NOTEBOOK_POLL_ATTEMPTS})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the notebook appears in the expected location in S3, we download it locally within the build instance, and the stdout and stderr output we got from running the notebook. This doesn't actually run the notebook, but will raise and surface any errors that we triggered during execution on the SM notebook instance. If your solution needs to run more than one notebook you would need to wait for each one to finish in the order you expect them to execute, download them, then dry-run them sequentially here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry-run execute the notebook, raising errors if any existed\n",
    "import papermill as pm\n",
    "\n",
    "logging.info(\"Downloading notebook outputs locally...\")\n",
    "s3.meta.client.download_file(CI_BUCKET, os.path.join(prefix, key), key)\n",
    "try:\n",
    "    s3.meta.client.download_file(CI_BUCKET, os.path.join(prefix, \"output_stdout.txt\"), \"output_stdout.txt\")\n",
    "    s3.meta.client.download_file(CI_BUCKET, os.path.join(prefix, \"output_stderr.txt\"), \"output_stderr.txt\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# TODO: this notebook filename should also be a parameter\n",
    "logging.info(\"Performing dry-run of notebooks to surface any errors...\")\n",
    "nb = pm.iorw.load_notebook_node(key)\n",
    "pm.execute.raise_for_execution_errors(nb, key)\n",
    "\n",
    "print(\"Test deployment and notebook execution completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build project's artifacts will include all the files you download locally here, so they will end up on S3, where you can go and check out the output to debug any errors in this or the solution's notebook. You can find the build artifacts by browsing to the CI build stage in your pipeline."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}